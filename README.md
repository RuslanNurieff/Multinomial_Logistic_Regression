# Multinomial Logistic Regression

The project is part of the "Optimization for Data Science" master's class.

## Description

There are numerous approaches for optimizing the classic and multinomial logistic regression, one of them being coordinate descent. In this project, both gradient descent and coordinate descent (Gauss-Southwell) methods are used and compared. In contrast to fixed step size, Armijo line search is also explored. More about the theoretical details and results can be found in the report PDF.

## Getting Started

### Dependencies

* The project could be uploaded and run on Colab or on Jupyter Notebook locally. Refer to https://docs.anaconda.com/anaconda/install/windows/ for configuring Anaconda on your system.

## Authors

Ruslan Nuriev

## Acknowledgments

* [Distance Based Outliers](https://www.researchgate.net/publication/225179594_Distance-Based_Outliers_Algorithms_and_Applications)
* [Farthest First Traversal](https://github.com/xuwd11/Coursera-Bioinformatics/blob/master/51_01_FarthestFirstTraversal.py)
* [Reservoir Sampling](https://cesa-bianchi.di.unimi.it/Algo2/Note/reservoir.pdf)
* [Reservoir Sampling & Sticky Sampling](https://www.dei.unipd.it/~geppo/PrAvAlg/DOCS/DFchapter08.pdf)
* [Resilient Distributed Dataset](https://spark.apache.org/docs/latest/rdd-programming-guide.html)
* [Spark Streaming](https://spark.apache.org/docs/latest/streaming-programming-guide.html)
